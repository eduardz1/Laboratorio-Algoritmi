\documentclass[12pt, letterpaper]{report}
\usepackage[utf8]{inputenc}
\usepackage{tikz}
\usepackage{titlesec}
\usepackage{float}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{color}

\definecolor{mygreen}{RGB}{154,255,77}
\definecolor{mygray}{gray}{0.5}
\definecolor{myblue}{RGB}{41,141,255}

\lstset{
    language=C++,
    basicstyle=\tiny,
    keywordstyle=\color{myblue},
    commentstyle=\color{mygray},
    numberstyle=\color{mygreen},
    numbers=left,
    numberstyle=\tiny\color{mygray},
    breaklines=true,
    breakatwhitespace=true,
    tabsize=2
}

\renewcommand{\thesection}{\arabic{section}} % removes reference of \chapter to avoid "0."
\titleformat{\chapter}{\normalfont\huge}{\thechapter}{20pt}{\huge\it}

\title{Relazione Algoritmi e Strutture Dati}
\author{Eduard Antonovic Occhipinti, Iman Solaih, Marco Molica}

\begin{document}
\maketitle
\tableofcontents

\chapter*{Esercizio 1}
\section{Quick Sort}
Il \verb|quick_sort()| è un algoritmo che ordina una collezione partendo da un pivot, 
il pivot può essere scelto in vari modi, e in base a quale viene scelto il tempo
di sorting varia. Il \verb|quick_sort()| utilizza \verb|_part()| per scegliere il pivot prima 
di chiamare \verb|partition()| per dividere gli elementi del range selezionato 
in un sottoinsieme di elementi maggiori e uno di elementi minori del pivot
la cui posizione finale viene restituita dal metodo.
\newline
Premessa: nella seguente relazione analizzeremo solo i dati raccolti su records
favorendo il primo \verb|field| nell'ordinamento, i dati per i restanti due field
sono equivalenti ma con costanti minori.

\newpage
\subsection{Impatto della scelta del pivot nel quick sort}
La chiamata a \verb|rand()| porta il \verb|quick_sort()| con pivot scelto 
randomicamente o come mediana di tre numeri ad essere mediamente più lento 
rispetto agli altri 3 casi presi in considerazione. La tabella sottostante 
riporta il tempo impiegato ad ordinare un array di 20 milioni elementi di tipo \verb|struct Record|
\begin{figure}[H]
\centering
    \include{figures/qs_boxplot_pivot}
\end{figure}

\newpage
La scelta del pivot diventa importante quando l'array in input risulta già
parzialmente o totalmente ordinato.
Il grafico sottostante riporta il tempo impiegato da \verb|quick_sort()| 
per scorrere un array già ordinato. Come ci aspettiamo, l'algoritmo degenera ad
$O(n^2)$, sia \verb|LAST| che \verb|FIRST| generano un grafico esponenziale ma con
costanti diverse, fosse l'array ordinato in ordine inverso ci aspettiamo il comportamento
opposto tra questi due.
\begin{figure}[H]
\centering
    \include{figures/qs_plot_pivot}
\end{figure}
Concentrandoci in particolare sui pivot \verb|median of 3|, \verb|random| e \verb|middle|, 
possiamo notare che per questi il tempo cresce in maniera costante.  
\begin{figure}[H]
\centering
    \include{figures/qs_plot_zoommed_pivot}
\end{figure}
In particolare \verb|MIDDLE| è chiaramente il pivot con perfomance migliori, il risultato è quello
aspettato considerando che in questo contesto qui, \verb|partition()| non deve
praticamente effettuare \verb|SWAP|. Possiamo comunque notare che il pivot \verb|RANDOM|
si comporta discretamente, con una variabilità maggiore rispetto agli altri. \verb|MEDIAN3|
finirà per sceglire lo stesso pivot di \verb|MIDDLE| e quindi il tempo aggiuntivo
è interamente introdotto dall'overhead causato dal confronto dell'elemento centrale
con il first e last dell'array.

\newpage
\subsection{Fallback a Insertion Sort}
Quando il \verb|quick_sort()| lavora su un range sufficientemente piccolo, è più
efficiente utilizzare il \verb|insert_sort()|. Il range di cutoff è stato impostato a 8 elementi.

\subsection{Scelta del partition}
Nel nostro dataset ogni \verb|record| è virtualmente univoco, la partition di Lomuto
si comporta quindi molto bene ed anzi, secondo i nostri test, anche meglio di quella
di Hoare, nonostante quest'ultima infatti effettua meno SWAP, è più complessa a
livello di codice e causa alla CPU una probabilità più alta di branch misprediction.

\begin{lstlisting}
    template <typename T>
    int partition_lomuto(T array, int left, int right)
    {
        T pivot = array[right];
        int i = left - 1;
        for (int j = left; j < right; j++){
            if (array[j] <= pivot) {
                i++;
                swap(&array[i], &array[j]);
            }
        }
        swap(&array[i + 1], &array[right]);
        return i + 1;
    }
\end{lstlisting}

Nel caso però si lavorasse su un dataset con una quantità importante di elementi
duplicati, la partition di Hoare inizia subito ad avere perfomance molto migliori,
una buona alternativa è anche una partition di Lomuto modificata in maniera tale
da restituire due indici, dividendo quindi il subarray in tre parti:
elementi minori, uguali e maggiori del pivot.

\begin{lstlisting}
    template <typename T>
    int partition_hoare(T array, int left, int right)
    {
        T pivot = array[(left + right) / 2];
        int i = left - 1;
        int j = right + 1;
        while (1) {
            do {
                i++;
            } while (array[i] < pivot);
            do {
                j--;
            } while (array[j] > pivot);
            if (i >= j) {
                return j;
            }
            swap(&array[i], &array[j]);
        }
    }
\end{lstlisting}

\newpage
\section{Binary Insertion Sort}`
Essendo l'algoritmo di complessità $O(n^2)$, non ci aspettiamo che finisca in tempi
sensati l'ordinamento dei 20 milioni di records, facendo due calcoli sui nostri computer
dovrebbe metterci approssimativmaente 2 anni.
Nel seguente schema possiamo però notare come la ricerca binaria del punto di inserimento
migliori notevolmente la costante di tempo.
\begin{figure}[H]
\centering
    \include{figures/bi_plot_unsorted}
\end{figure}

\chapter*{Esercizio 2}

\section{Skip List}

Bla bla bla insertion time decresce in maniera importante
\begin{figure}[H]
\centering
    \include{figures/sklist_insert}
\end{figure}

Bla bla bla in particolare zoommando sui livelli più di interesse ci rendiamo conto
che la distribuzione è concentrata attorno a 19
\begin{figure}[H]
\centering
    \include{figures/sklist_zoommed_insert}
\end{figure}

Bla bla bla facendo un grafico delle medie dei tempi di inserimento notiamo che 18
è il numero ottimale di livelli
\begin{figure}[H]
\centering
    \include{figures/sklist_mean_insert}
\end{figure}

Bla bla bla search time decresce in maniera imporante
\begin{figure}[H]
\centering
    \include{figures/sklist_search}
\end{figure}

Bla bla bla in particolare zoommando sui livelli più di interesse ci rendiamo conto
che la distribuzione è concentrata attorno a 19
\begin{figure}[H]
\centering
    \include{figures/sklist_zoommed_search}
\end{figure}

Bla bla bla facendo un grafico delle medie dei tempi di inserimento notiamo che 17
è il numero ottimale di livelli
\begin{figure}[H]
\centering
    \include{figures/sklist_mean_search}
\end{figure}

Sorprendentemente il numero ottimale di livelli non coincide esattamente con $ln(n)$

\chapter*{Esercizio 3}
\section{Minimum Heap}

\chapter*{Esercizio 4}
\section{Graph}

\end{document}