\documentclass[12pt, letterpaper]{report}
\usepackage[utf8]{inputenc}
\usepackage{tikz}
\usepackage{titlesec}
\usepackage{float}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{color}

\definecolor{mygreen}{RGB}{154,255,77}
\definecolor{mygray}{gray}{0.5}
\definecolor{myblue}{RGB}{41,141,255}

\lstset{
    language=C++,
    basicstyle=\tiny,
    keywordstyle=\color{myblue},
    commentstyle=\color{mygray},
    numberstyle=\color{mygreen},
    numbers=left,
    numberstyle=\tiny\color{mygray},
    breaklines=true,
    breakatwhitespace=true,
    tabsize=2
}

\renewcommand{\thesection}{\arabic{section}} % removes reference of \chapter to avoid "0."
\titleformat{\chapter}{\normalfont\huge}{\thechapter}{20pt}{\huge\it}

\title{Relazione Algoritmi e Strutture Dati}
\author{Eduard Antonovic Occhipinti, Iman Solaih, Marco Molica}

\begin{document}
\maketitle
\tableofcontents

\chapter*{Esercizio 1}
\section{Quick Sort}
Il \verb|quick_sort()| √® un algoritmo che ordina una collezione partendo da un pivot,
questo pu√≤ essere scelto in vari modi, e in base a quale viene scelto il tempo
di sorting varia. Il \verb|quick_sort()| utilizza \verb|_part()| per scegliere il pivot prima 
di chiamare \verb|partition()| per dividere gli elementi del range selezionato 
in un sottoinsieme di elementi maggiori e uno di elementi minori del pivot
la cui posizione finale viene restituita dal metodo.
\newline
\newline
Premessa: nella seguente relazione analizzeremo solo i dati raccolti su records
favorendo il primo \verb|field| nell'ordinamento, i dati per i restanti due field
sono equivalenti ma con costanti minori.

\newpage
\subsection{Impatto della scelta del pivot nel quick sort}
La tabella sottostante riporta il tempo impiegato ad ordinare un array di 
20 milioni elementi di tipo \verb|struct Record|
\begin{figure}[H]
\centering
    \include{figures/qs_boxplot_pivot}
\end{figure}
\newpage

La scelta del pivot diventa importante quando l'array in input risulta gi√†
parzialmente o totalmente ordinato.
Il grafico sottostante riporta il tempo impiegato da \verb|quick_sort()| 
per scorrere un array gi√† ordinato. Come ci aspettiamo, l'algoritmo degenera ad
$O(n^2)$, sia \verb|LAST| che \verb|FIRST| generano un grafico esponenziale ma con
costanti diverse, fosse l'array ordinato in ordine inverso ci aspettiamo il comportamento
opposto tra questi due.
\begin{figure}[H]
\centering
    \include{figures/qs_plot_pivot}
\end{figure}
Concentrandoci in particolare sui pivot \verb|median of 3|, \verb|random| e \verb|middle|, 
possiamo notare che per questi il tempo cresce in maniera costante.  
\begin{figure}[H]
\centering
    \include{figures/qs_plot_zoommed_pivot}
\end{figure}
In particolare \verb|MIDDLE| √® chiaramente il pivot con perfomance migliori, 
il risultato √® quello aspettato considerando che in questo contesto qui, 
\verb|partition()| non deve praticamente effettuare \verb|SWAP|. 
Possiamo comunque notare che il pivot \verb|RANDOM| si comporta discretamente, 
con una variabilit√† maggiore rispetto agli altri. \verb|MEDIAN3|
finir√† per sceglire lo stesso pivot di \verb|MIDDLE| e quindi il tempo aggiuntivo
√® interamente introdotto dall'overhead causato dal confronto dell'elemento centrale
con il first e last dell'array.

\newpage
\subsection{Fallback a Insertion Sort}
Quando il \verb|quick_sort()| lavora su un range sufficientemente piccolo, √® pi√π
efficiente utilizzare il \verb|insert_sort()|. Il range di cutoff √® stato impostato a 8 elementi.

\subsection{Scelta del partition}
Nel nostro dataset ogni \verb|record| √® virtualmente univoco, la partition di Lomuto
si comporta quindi molto bene ed anzi, secondo i nostri test, anche meglio di quella
di Hoare, nonostante quest'ultima infatti effettua meno \verb|SWAP|, √® pi√π complessa a
livello di codice e causa alla CPU una probabilit√† pi√π alta di branch misprediction.

\begin{lstlisting}
    template <typename T>
    int partition_lomuto(T array[], int left, int right)
    {
        T pivot = array[right];
        int i = left - 1;
        for (int j = left; j < right; j++){
            if (array[j] <= pivot) {
                i++;
                swap(&array[i], &array[j]);
            }
        }
        swap(&array[i + 1], &array[right]);
        return i + 1;
    }
\end{lstlisting}

Nel caso per√≤ si lavorasse su un dataset con una quantit√† importante di elementi
duplicati, la partition di Hoare inizia subito ad avere perfomance molto migliori,
una buona alternativa √® anche una partition di Lomuto modificata in maniera tale
da restituire due indici, dividendo quindi il subarray in tre parti:
elementi minori, uguali e maggiori del pivot.

\begin{lstlisting}
    template <typename T>
    int partition_hoare(T array[], int left, int right)
    {
        T pivot = array[(left + right) / 2];
        int i = left - 1;
        int j = right + 1;
        while (1) {
            do {
                i++;
            } while (array[i] < pivot);
            do {
                j--;
            } while (array[j] > pivot);
            if (i >= j) {
                return j;
            }
            swap(&array[i], &array[j]);
        }
    }
\end{lstlisting}

\newpage
\section{Binary Insertion Sort}`
Essendo l'algoritmo di complessit√† $O(n^2)$, non ci aspettiamo che finisca in tempi
sensati l'ordinamento dei 20 milioni di records, facendo due calcoli sui nostri computer
dovrebbe metterci approssimativmaente 2 anni.
Nel seguente schema possiamo per√≤ notare come la ricerca binaria del punto di inserimento
migliori notevolmente la costante di tempo.
\begin{figure}[H]
\centering
    \include{figures/bi_plot_unsorted}
\end{figure}

\chapter*{Esercizio 2}

\section{Skip List}
Dagli esperimenti effettuati i risultati dell'insertion mostrano come 
all'aumentare dei livelli il tempo di inserimento decresce in maniera esponenziale.
\begin{figure}[H]
\centering
    \include{figures/sklist_insert}
\end{figure}

Dal grafico si nota come la distribuzione dei livelli raggiunti √® concentrata 
attorno a 20, inoltre dal livello 30 in poi i livelli non vengono quasi mai raggiunti, 
difatti la probabilit√† di raggiungere ogni livello √® $\frac{1}{2^n}$, il livello
32, il massimo raggiunto, aveva probabilit√† $2.32 \times 10^{-10}$.
% üêñ (-(00)-) ewe TwT UwU  OwO B) :3 ywy üêé ü¶ö üê¨ ü¶π
% (._. ) ü§∫  (^_^') (>__>) (^x^ ) :-p~ 
% ‚°Ü‚£ê‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚†Ö‚¢ó‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚†ï‚†ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï
% ‚¢ê‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚£ï‚¢ï‚¢ï‚†ï‚†Å‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚†Ö‚°Ñ‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï
% ‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚†Ö‚¢ó‚¢ï‚†ï‚£†‚†Ñ‚£ó‚¢ï‚¢ï‚†ï‚¢ï‚¢ï‚¢ï‚†ï‚¢†‚£ø‚†ê‚¢ï‚¢ï‚¢ï‚†ë‚¢ï‚¢ï‚†µ‚¢ï
% ‚¢ï‚¢ï‚¢ï‚¢ï‚†Å‚¢ú‚†ï‚¢Å‚£¥‚£ø‚°á‚¢ì‚¢ï‚¢µ‚¢ê‚¢ï‚¢ï‚†ï‚¢Å‚£æ‚¢ø‚£ß‚†ë‚¢ï‚¢ï‚†Ñ‚¢ë‚¢ï‚†Ö‚¢ï
% ‚¢ï‚¢ï‚†µ‚¢Å‚†î‚¢Å‚£§‚£§‚£∂‚£∂‚£∂‚°ê‚£ï‚¢Ω‚†ê‚¢ï‚†ï‚£°‚£æ‚£∂‚£∂‚£∂‚£§‚°Å‚¢ì‚¢ï‚†Ñ‚¢ë‚¢Ö‚¢ë
% ‚†ç‚£ß‚†Ñ‚£∂‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£∑‚£î‚¢ï‚¢Ñ‚¢°‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£¶‚°ë‚¢ï‚¢§‚†±‚¢ê
% ‚¢†‚¢ï‚†Ö‚£æ‚£ø‚†ã‚¢ø‚£ø‚£ø‚£ø‚†â‚£ø‚£ø‚£∑‚£¶‚£∂‚£Ω‚£ø‚£ø‚†à‚£ø‚£ø‚£ø‚£ø‚†è‚¢π‚£∑‚£∑‚°Ö‚¢ê
% ‚£î‚¢ï‚¢•‚¢ª‚£ø‚°Ä‚†à‚†õ‚†õ‚†Å‚¢†‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚°Ä‚†à‚†õ‚†õ‚†Å‚†Ñ‚£º‚£ø‚£ø‚°á‚¢î
% ‚¢ï‚¢ï‚¢Ω‚¢∏‚¢ü‚¢ü‚¢ñ‚¢ñ‚¢§‚£∂‚°ü‚¢ª‚£ø‚°ø‚†ª‚£ø‚£ø‚°ü‚¢Ä‚£ø‚£¶‚¢§‚¢§‚¢î‚¢û‚¢ø‚¢ø‚£ø‚†Å‚¢ï
% ‚¢ï‚¢ï‚†Ö‚£ê‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚£ø‚£ø‚°Ñ‚†õ‚¢Ä‚£¶‚†à‚†õ‚¢Å‚£º‚£ø‚¢ó‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚¢ï‚°è‚£ò‚¢ï
% ‚¢ï‚¢ï‚†Ö‚¢ì‚£ï‚£ï‚£ï‚£ï‚£µ‚£ø‚£ø‚£ø‚£æ‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£∑‚£ï‚¢ï‚¢ï‚¢ï‚¢ï‚°µ‚¢Ä‚¢ï‚¢ï
% ‚¢ë‚¢ï‚†É‚°à‚¢ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚¢É‚¢ï‚¢ï‚¢ï
% ‚£Ü‚¢ï‚†Ñ‚¢±‚£Ñ‚†õ‚¢ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚£ø‚†ø‚¢Å‚¢ï‚¢ï‚†ï‚¢Å
% ‚£ø‚£¶‚°Ä‚£ø‚£ø‚£∑‚£∂‚£¨‚£ç‚£õ‚£õ‚£õ‚°õ‚†ø‚†ø‚†ø‚†õ‚†õ‚¢õ‚£õ‚£â‚£≠‚£§‚£Ç‚¢ú‚†ï‚¢ë‚£°‚£¥‚£ø
\begin{figure}[H]
\centering
    \include{figures/sklist_zoommed_insert}
\end{figure}

Bla bla bla facendo un grafico delle medie dei tempi di inserimento notiamo che 18
√® il numero ottimale di livelli
\begin{figure}[H]
\centering
    \include{figures/sklist_mean_insert}
\end{figure}

Bla bla bla search time decresce in maniera imporante
\begin{figure}[H]
\centering
    \include{figures/sklist_search}
\end{figure}

Bla bla bla in particolare zoommando sui livelli pi√π di interesse ci rendiamo conto
che la distribuzione √® concentrata attorno a 19
\begin{figure}[H]
\centering
    \include{figures/sklist_zoommed_search}
\end{figure}

Bla bla bla facendo un grafico delle medie dei tempi di inserimento notiamo che 17
√® il numero ottimale di livelli
\begin{figure}[H]
\centering
    \include{figures/sklist_mean_search}
\end{figure}

Sorprendentemente il numero ottimale di livelli non coincide esattamente con $ln(n)$

\chapter*{Esercizio 3}
\section{Minimum Heap}

\chapter*{Esercizio 4}
\section{Graph}

\end{document}